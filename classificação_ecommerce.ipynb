{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MggtUfstIRdn"
      },
      "source": [
        "####intalações e importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CAKM9t2gvbzf"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets\n",
        "!pip install colorgram.py\n",
        "!pip install imagehash\n",
        "!pip install opencv-python\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2gfwU0A9IQs_"
      },
      "outputs": [],
      "source": [
        "import opendatasets as od\n",
        "import os\n",
        "from PIL import Image\n",
        "import subprocess\n",
        "import imghdr\n",
        "import random\n",
        "from collections import Counter\n",
        "import colorgram\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import imagehash\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "import tensorflow as tf\n",
        "from sklearn.decomposition import PCA\n",
        "import shutil\n",
        "from concurrent.futures import ThreadPoolExecutor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UtwCMKa7vyxU"
      },
      "outputs": [],
      "source": [
        "od.download(\"https://www.kaggle.com/datasets/fatihkgg/ecommerce-product-images-18k\")\n",
        "\n",
        "#USAR API TOKEN DO KAGGLE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2DbowIZCOG4"
      },
      "source": [
        "Dataset em  /content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQK9tRfvbWv6"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES'\n",
        "train_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train\"\n",
        "val_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/val\"\n",
        "test_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APdfWgpjB5ki"
      },
      "source": [
        "# Parte 1 - Análise do DataSet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAqP_BIlDlr6"
      },
      "source": [
        "## Objetivo e informações esperadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htOu5f-OD6pq"
      },
      "source": [
        "Objetivo:\n",
        "* Apresentar informações do dataset.\n",
        "\n",
        "Informações esperadas:\n",
        "* Integridade dos Arquivos\n",
        "  1. Verifique se todas as imagens listadas no arquivo de informações\n",
        "realmente existem no diretório de imagens e vice-versa.\n",
        "  2. Verifique se todas as imagens estão no mesmo formato, ex: JPEG,\n",
        "PNG, etc.\n",
        "* Consistência dos Metadados\n",
        "  1. Verifique se há valores ausentes nos metadados e como esses casos\n",
        "são tratados.\n",
        "  2. Verifique valores inconsistentes, por exemplo: dimensões de imagens\n",
        "fora do esperado.\n",
        "* Qualidade das Imagens\n",
        "  1. Identifique imagens corrompidas que não podem ser abertas ou\n",
        "processadas.\n",
        "* Distribuição das Classes\n",
        "  1. Verifique a distribuição das classes para identificar possíveis\n",
        "desequilíbrios que possam afetar a modelagem\n",
        "* Duplicatas\n",
        "  1. Identifique imagens duplicadas que possam enviesar os resultados.\n",
        "  2. Verifique duplicatas no arquivo de informações.\n",
        "\n",
        "Informações complementares:\n",
        "* Elaborar uma apresentação para mostrar os resultados.\n",
        "* Apresentar o dataset de forma detalhada.\n",
        "* Verifique quais itens em Informações esperadas podem ser aplicados no\n",
        "dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8IhDPpHS5lm"
      },
      "source": [
        "## **Integridade dos Arquivos**\n",
        "A função a seguir verifica se todas as imagens no diretório estão no mesmo formato (JPEG, JPG, PNG). Ela retorna um dicionário com os formatos das imagens como chaves e suas respectivas quantidades como valores.\n",
        "\n",
        "Saída esperada: {'JPEG': 18175}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNPu1t5YRZks"
      },
      "outputs": [],
      "source": [
        "def verificar_formato_imagem(data):\n",
        "    formatos = {}\n",
        "    for raiz, dirs, arquivos in os.walk(data):\n",
        "        print(raiz)\n",
        "        for arquivo in arquivos:\n",
        "            if arquivo.endswith(('jpeg', 'jpg', 'png')):\n",
        "                caminho_arquivo = os.path.join(raiz, arquivo)\n",
        "                with Image.open(caminho_arquivo) as img:\n",
        "                    formato = img.format\n",
        "                    if formato not in formatos:\n",
        "                        formatos[formato] = 0\n",
        "                    formatos[formato] += 1\n",
        "            else:\n",
        "                formatos['Desconhecido'] = formatos.get('Desconhecido', 0) + 1\n",
        "\n",
        "    return formatos\n",
        "\n",
        "formatos_imagens = verificar_formato_imagem(data_dir)\n",
        "print(formatos_imagens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h1ZERpxr50AR"
      },
      "source": [
        "## **Consistência dos Metadados**\n",
        "\n",
        "Nessa etapa, foi analisado a qualidade e a integridade das imagens, para assegurar que não haverá maiores problemas nas etapas seguintes.\n",
        "\n",
        "Foram levantados os seguintes:\n",
        "\n",
        "\n",
        "*   Dimensões das imagens\n",
        "*   Quantidade de megapixes\n",
        "*   Recorrência de cores\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2EvBVCB8pue"
      },
      "source": [
        "#### **Dimensão das imagens**\n",
        "\n",
        "Utilizando o conjunto de imagens amostrais, presentes na pasta (train), não foi encontrado alguma inconsistência, uma vez que o conjunto amostral apresenta imagens com as mesmas dimensões.\n",
        "\n",
        "---\n",
        "*Saída Esperada*:\n",
        "\n",
        "\n",
        "```\n",
        "A dimensão que mais aparece é: (224, 224) (quantidade: 18175)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHoS2wfA8CeV"
      },
      "outputs": [],
      "source": [
        "\n",
        "def verificar_dimensoes_imagem(caminho_item):\n",
        "    try:\n",
        "        with Image.open(caminho_item) as img:\n",
        "            largura, altura = img.size\n",
        "        return (largura, altura)\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao processar {caminho_item}: {e}\")\n",
        "        return None\n",
        "\n",
        "def processar_imagens(pasta):\n",
        "    contagem_dimensoes = Counter()\n",
        "    with ThreadPoolExecutor() as executor:\n",
        "        futures = []\n",
        "        for subdir, _, arquivos in os.walk(pasta):\n",
        "            for arquivo in arquivos:\n",
        "                caminho_item = os.path.join(subdir, arquivo)\n",
        "                if caminho_item.lower().endswith(('.jpeg', '.jpg', '.png')):\n",
        "                    futures.append(executor.submit(verificar_dimensoes_imagem, caminho_item))\n",
        "\n",
        "        for future in futures:\n",
        "            resultado = future.result()\n",
        "            if resultado:\n",
        "                largura, altura = resultado\n",
        "                contagem_dimensoes[(largura, altura)] += 1\n",
        "\n",
        "    return contagem_dimensoes\n",
        "\n",
        "# Processar as imagens\n",
        "contagem_dimensoes = Counter()\n",
        "contagem_dimensoes.update(processar_imagens(train_dir))\n",
        "contagem_dimensoes.update(processar_imagens(val_dir))\n",
        "contagem_dimensoes.update(processar_imagens(check_dir))\n",
        "\n",
        "# Determinar a dimensão mais comum\n",
        "dimensao_mais_comum = contagem_dimensoes.most_common(1)[0]\n",
        "total_imagens = sum(contagem_dimensoes.values())\n",
        "\n",
        "# Exibir o resultado\n",
        "print(f\"A dimensão que mais aparece é: {dimensao_mais_comum[0]} (quantidade: {dimensao_mais_comum[1]})\")\n",
        "print(f\"Total de imagens processadas: {total_imagens}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vh6fkU3a7yWv"
      },
      "source": [
        "#### **Quantidade de MegaPixels**\n",
        "\n",
        "Também não foi encontrado dados ausentes ou inconsistentes nesse espaço de dados amostral, uma vez que todas as imagens apresentam a mesma quantidade de megapixels.\n",
        "\n",
        "---\n",
        "*Saída Esperada:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Todos os arquivos possuem 0.050 megapixels.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NHUdnZJa_cdW"
      },
      "outputs": [],
      "source": [
        "megapixels_esperado = None\n",
        "arquivos_com_megapixels_diferentes = []\n",
        "\n",
        "def verificar_megapixels(pasta):\n",
        "    global megapixels_esperado, arquivos_com_megapixels_diferentes\n",
        "\n",
        "    for item in os.listdir(pasta):\n",
        "        caminho_item = os.path.join(pasta, item)\n",
        "\n",
        "        if os.path.isdir(caminho_item):\n",
        "            verificar_megapixels(caminho_item)\n",
        "        elif os.path.isfile(caminho_item) and caminho_item.lower().endswith(('.jpeg', '.jpg')):\n",
        "            try:\n",
        "                with Image.open(caminho_item) as img:\n",
        "                    largura, altura = img.size\n",
        "                    megapixels_atual = (largura * altura) / 1_000_000  # Converte para megapixels\n",
        "\n",
        "                    if megapixels_esperado is None:\n",
        "                        megapixels_esperado = megapixels_atual\n",
        "                    elif megapixels_atual != megapixels_esperado:\n",
        "                        arquivos_com_megapixels_diferentes.append(caminho_item)\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar {caminho_item}: {e}\")\n",
        "\n",
        "# Verificar as pastas\n",
        "verificar_megapixels(train_dir)\n",
        "verificar_megapixels(val_dir)\n",
        "verificar_megapixels(check_dir)\n",
        "\n",
        "if arquivos_com_megapixels_diferentes:\n",
        "    print(\"Nem todos os arquivos possuem o mesmo valor de megapixels.\")\n",
        "    print(\"Arquivos com megapixels diferentes:\")\n",
        "    for arquivo in arquivos_com_megapixels_diferentes:\n",
        "        print(f\"  - {arquivo}\")\n",
        "else:\n",
        "    print(f\"Todos os arquivos possuem {megapixels_esperado:.2f} megapixels.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmSO99PpAOSo"
      },
      "source": [
        "#### **Recorrência de Cores**\n",
        "\n",
        "Nesse levantamento, foi observado que as cores semelhantes ao branco absoluto são as mais presentes nas categorias apresentadas. O algoritmo utilizado analisa a imagem como um todoo, por isso, o fundo \"neutro\" influênciou nesse resultado. Porém, utilizando o *OpenCV*, é possível detectar os contornos do produto e descobrir as cores além do fundo neutro.\n",
        "\n",
        "\n",
        "---\n",
        "*Saída utilizando apenas a biblioteca Colorgram:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Categoria 'BABY_PRODUCTS': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 3.05\n",
        "Categoria 'BEAUTY_HEALTH': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 2.03\n",
        "Categoria 'CLOTHING_ACCESSORIES_JEWELLERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 6.29\n",
        "Categoria 'ELECTRONICS': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 4.57\n",
        "Categoria 'GROCERY': Cor predominante: Rgb(r=254, g=254, b=253), Proporção total: 9.50\n",
        "Categoria 'HOBBY_ARTS_STATIONERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 2.84\n",
        "Categoria 'HOME_KITCHEN_TOOLS': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 8.90\n",
        "Categoria 'PET_SUPPLIES': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 2.11\n",
        "Categoria 'SPORTS_OUTDOOR': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 12.45\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9LDhAGFCpwQ"
      },
      "outputs": [],
      "source": [
        "def analisar_cores_por_categoria(pasta):\n",
        "    dados = []\n",
        "\n",
        "    for nome_subpasta in os.listdir(pasta):\n",
        "        caminho_subpasta = os.path.join(pasta, nome_subpasta)\n",
        "        if os.path.isdir(caminho_subpasta):\n",
        "            categoria = nome_subpasta\n",
        "\n",
        "            for item in os.listdir(caminho_subpasta):\n",
        "                caminho_item = os.path.join(caminho_subpasta, item)\n",
        "                if os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "                    try:\n",
        "                        cores = colorgram.extract(Image.open(caminho_item), 5)  # Extrai 5 cores\n",
        "\n",
        "                        for cor in cores:\n",
        "                            dados.append({'categoria': categoria, 'cor_predominante': cor.rgb, 'proporcao': cor.proportion})\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao processar a imagem {caminho_item}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(data_dir)\n",
        "\n",
        "    cores_predominantes_por_categoria = df.groupby(['categoria', 'cor_predominante'])['proporcao'].sum().reset_index()\n",
        "    cores_predominantes_por_categoria = cores_predominantes_por_categoria.loc[cores_predominantes_por_categoria.groupby('categoria')['proporcao'].idxmax()]\n",
        "\n",
        "    for _, row in cores_predominantes_por_categoria.iterrows():\n",
        "        print(f\"Categoria '{row['categoria']}': Cor predominante: {row['cor_predominante']}, Proporção total: {row['proporcao']:.2f}\")\n",
        "\n",
        "analisar_cores_por_categoria(train_dir)\n",
        "#analisar_cores_por_categoria(val_dir)\n",
        "#analisar_cores_por_categoria(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OOsd7cMTDH93"
      },
      "source": [
        "Após utilizar a ferramenta *OpenCV*, conseguimos observar que, apesar da maioria das categorias ainda seguir na paleta de cores \"branco\" ou \"cinza\", a  categoria \"BEAUTY_HEALTH\" tem uma predominância de cores mais vibrantes e quentes, como o amarelo alaranjado, que podem transmitir a ideia de saúde, vitalidade e beleza, enquanto \"BABY_PRODUCTS\" tem uma predominância de cores claras e neutras, como o branco e o cinza claro, que são comumente associadas a produtos para bebês.\n",
        "\n",
        "Cada categoria apresenta a seguinte variedade de cores:\n",
        "\n",
        "\n",
        "*   BABY_PRODUCTS - **Cinza claro.**\n",
        "*   HOME_KITCHEN_TOOLS - **Cinza bem claro.**\n",
        "*   GROCERY - **Um branco com tons de amarelo.**\n",
        "*   BEAUTY_HEALTH - **Dourado.**\n",
        "*   CLOTHING_ACCESSORIES_JEWELLERY, ELECTRONICS, HOBBY_ARTS_STATIONERY, PET_SUPPLIES e SPORTS_OUTDOOR - **Branco.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Saída Esperada:*\n",
        "\n",
        "\n",
        ">A proporção total indica o percentual que os metadados da categoria representam em relação ao total de dados.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Categoria 'BABY_PRODUCTS': Cor predominante: Rgb(r=237, g=237, b=236), Proporção total: 1.73\n",
        "Categoria 'BEAUTY_HEALTH': Cor predominante: Rgb(r=226, g=165, b=4), Proporção total: 1.20\n",
        "Categoria 'CLOTHING_ACCESSORIES_JEWELLERY': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 1.09\n",
        "Categoria 'ELECTRONICS': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 3.55\n",
        "Categoria 'GROCERY': Cor predominante: Rgb(r=254, g=254, b=253), Proporção total: 1.69\n",
        "Categoria 'HOBBY_ARTS_STATIONERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 1.20\n",
        "Categoria 'HOME_KITCHEN_TOOLS': Cor predominante: Rgb(r=251, g=251, b=250), Proporção total: 1.61\n",
        "Categoria 'PET_SUPPLIES': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 1.76\n",
        "Categoria 'SPORTS_OUTDOOR': Cor predominante: Rgb(r=252, g=252, b=252), Proporção total: 3.87\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jtyjw9EkDHjY"
      },
      "outputs": [],
      "source": [
        "def analisar_cores_por_categoria(pasta):\n",
        "    dados = []\n",
        "\n",
        "    for nome_subpasta in os.listdir(pasta):\n",
        "        caminho_subpasta = os.path.join(pasta, nome_subpasta)\n",
        "        if os.path.isdir(caminho_subpasta):\n",
        "            categoria = nome_subpasta\n",
        "\n",
        "            for item in os.listdir(caminho_subpasta):\n",
        "                caminho_item = os.path.join(caminho_subpasta, item)\n",
        "                if os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "                    try:\n",
        "                        img = cv2.imread(caminho_item)\n",
        "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                        _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "                        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                        if len(contours) > 0:\n",
        "                            maior_contorno = max(contours, key=cv2.contourArea)\n",
        "                            x, y, w, h = cv2.boundingRect(maior_contorno)\n",
        "                            img_recortada = img[y:y+h, x:x+w]\n",
        "\n",
        "                            cores = colorgram.extract(Image.fromarray(img_recortada), 5)\n",
        "\n",
        "                            for cor in cores:\n",
        "                                dados.append({'categoria': categoria, 'cor_predominante': cor.rgb, 'proporcao': cor.proportion})\n",
        "                        else:\n",
        "                            print(f\"Nenhum contorno encontrado na imagem {caminho_item}.\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao processar a imagem {caminho_item}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(dados)\n",
        "\n",
        "    cores_predominantes_por_categoria = df.groupby(['categoria', 'cor_predominante'])['proporcao'].sum().reset_index()\n",
        "    cores_predominantes_por_categoria = cores_predominantes_por_categoria.loc[cores_predominantes_por_categoria.groupby('categoria')['proporcao'].idxmax()]\n",
        "\n",
        "    for _, row in cores_predominantes_por_categoria.iterrows():\n",
        "        print(f\"Categoria '{row['categoria']}': Cor predominante: {row['cor_predominante']}, Proporção total: {row['proporcao']:.2f}\")\n",
        "\n",
        "analisar_cores_por_categoria(train_dir)\n",
        "#analisar_cores_por_categoria(val_dir)\n",
        "#analisar_cores_por_categoria(test_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwKzJIstGDAI"
      },
      "source": [
        "## **Qualidade de imagens**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6YaOOzndGqtP"
      },
      "outputs": [],
      "source": [
        "#Verifica se uma imagem pode ser aberta.\n",
        "def check_image(image_path):\n",
        "  try:\n",
        "    img = cv2.imread(image_path)\n",
        "    return img is not None\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao abrir {image_path}: {str(e)}\")\n",
        "    return False\n",
        "\n",
        "#Encontra imagens corrompidas em um diretório e seus subdiretórios.\n",
        "def find_corrupted_images(directory):\n",
        "  corrupted_images = []\n",
        "  for root, _, files in os.walk(directory):\n",
        "    for file in files:\n",
        "      if file.endswith(('.jpg', '.jpeg', '.png')):  # Adapte para outros formatos se necessário\n",
        "        image_path = os.path.join(root, file)\n",
        "        if not check_image(image_path):\n",
        "          corrupted_images.append(image_path)\n",
        "  return corrupted_images\n",
        "\n",
        "# Encontrando as imagens corrompidas em cada diretório\n",
        "corrupted_train = find_corrupted_images(train_dir)\n",
        "corrupted_val = find_corrupted_images(val_dir)\n",
        "corrupted_test = find_corrupted_images(test_dir)\n",
        "\n",
        "# Imprimindo ou salvando os resultados\n",
        "print(\"Imagens corrompidas no conjunto de treinamento:\")\n",
        "print(corrupted_train)\n",
        "\n",
        "print(\"Imagens corrompidas no conjunto de validação:\")\n",
        "print(corrupted_val)\n",
        "\n",
        "print(\"Imagens corrompidas no conjunto de teste:\")\n",
        "print(corrupted_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2kMdTKdakBr"
      },
      "source": [
        "##**Distribuição das Classes**\n",
        "Conjuntos de treinamento (train) e validação (val) para treinamento de modelo e ajuste de hiperparâmetros. E uma pequena amostra, conjunto de verificação (check) para avaliação visual do modelo durante a implantação.\n",
        "\n",
        "Aqui faremos uma análise da distribuição das imagens nessas classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TslbwNuMUEhu"
      },
      "source": [
        "####**TRAIN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNkPBNR064ak"
      },
      "source": [
        "Aqui contaremos quantas imagens possui em cada classe (diretórios)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oS8ujnAa23-"
      },
      "outputs": [],
      "source": [
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-bRIcq-7Fza"
      },
      "source": [
        "Criando um gráfico de barras para visualização da distribuição das classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk0zOzrBbBC4"
      },
      "outputs": [],
      "source": [
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Treinamento\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOBG30hN994w"
      },
      "source": [
        "Com a análise podemos observar que a classe GROCERY possui significativamente mais instâncias em comparação com as demais classes, sugerindo um desequilíbrio considerável na distribuição das classes no conjunto de dados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-U1ctGiN7n9u"
      },
      "source": [
        "### **CHECK - VAL**\n",
        "Faremos o mesmo para o conjunto de validação (val) e conjunto de verificação (check)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xd9N4unc7OBP"
      },
      "source": [
        "#### **VAL**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdVSfuRb89Cr"
      },
      "outputs": [],
      "source": [
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/val'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HsFjxJ4u9GLO"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Validação\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ni-LNizE9R7m"
      },
      "source": [
        "#### **CHECK**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hQ2SeaV9ltV"
      },
      "outputs": [],
      "source": [
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQJiv2iO9cOW"
      },
      "outputs": [],
      "source": [
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Verificação\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btBPDi0uw2l8"
      },
      "source": [
        "## **Duplicatas**\n",
        "\n",
        "\n",
        "1.   Identifique imagens duplicadas que possam enviesar os resultados.\n",
        "\n",
        "2.   Verifique duplicatas no arquivo de informações."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HXDlFYENePxp"
      },
      "outputs": [],
      "source": [
        "hashes = {}\n",
        "duplicatas = []\n",
        "\n",
        "# Itera sobre as pastas (classes)\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        # Itera sobre as imagens dentro da pasta da classe\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            try:\n",
        "                # Carrega a imagem\n",
        "                with Image.open(image_path) as img:\n",
        "                    # Calcula o hash perceptual da imagem\n",
        "                    image_hash = imagehash.average_hash(img)\n",
        "\n",
        "                # Verifica se o hash já existe no dicionário\n",
        "                if image_hash in hashes:\n",
        "                    # Se o hash já existir, marca a imagem como duplicada\n",
        "                    duplicatas.append((image_path, hashes[image_hash]))\n",
        "                else:\n",
        "                    # Se o hash não existir, adiciona ao dicionário\n",
        "                    hashes[image_hash] = image_path\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao processar a imagem: {image_path}. Erro: {e}\")\n",
        "                continue\n",
        "\n",
        "# Imprime as duplicatas encontradas\n",
        "if duplicatas:\n",
        "    print(\"Imagens duplicadas encontradas:\")\n",
        "    for dup in duplicatas:\n",
        "        print(f\"Duplicada: {dup[0]} \\nOriginal: {dup[1]}\\n\")\n",
        "else:\n",
        "    print(\"Nenhuma imagem duplicada encontrada.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nefWFz2KW27T"
      },
      "source": [
        "##Resolução de Problemas encontrados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldCUOmLEYQ3v"
      },
      "source": [
        "###Duplicatas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gRzVk98vYWdy"
      },
      "outputs": [],
      "source": [
        "for dup in duplicatas:\n",
        "    if os.path.dirname(dup[0]) == os.path.dirname(dup[1]):\n",
        "        if os.path.exists(dup[0]):\n",
        "            os.remove(dup[0])\n",
        "            print(f\"Imagem duplicada removida: {dup[0]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gawjt6l8amHi"
      },
      "source": [
        "###Balanceamento de Classes\n",
        "\n",
        "O código cria um gerador de dados de treinamento com data augmentation, aplicando técnicas como rotação, deslocamento e zoom para aumentar a diversidade das imagens. Em seguida, calcula os pesos das classes para corrigir desbalanceamentos no conjunto de dados e imprime esses pesos em um dicionário. O data augmentation é utilizado para melhorar a capacidade do modelo de generalizar e evitar que ele aprenda apenas características específicas da base de dados, tornando-o mais robusto e capaz de se adaptar a novas bases de dados semelhantes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHoDWEwMbvcf"
      },
      "outputs": [],
      "source": [
        "# Nome da classe que será reduzida\n",
        "classe_alvo = \"GROCERY\"\n",
        "\n",
        "# Função para calcular a distribuição de imagens por classe\n",
        "def calcular_distribuicao_imagens(train_dir):\n",
        "    distrib_classes = {}\n",
        "    for classe in os.listdir(train_dir):\n",
        "        classe_dir = os.path.join(train_dir, classe)\n",
        "        if os.path.isdir(classe_dir):\n",
        "            distrib_classes[classe] = len(os.listdir(classe_dir))\n",
        "    return distrib_classes\n",
        "\n",
        "# Função para cortar o número de imagens na classe alvo até atingir o novo total desejado\n",
        "def cortar_imagens_para_balanceamento(train_dir, classe_alvo, novo_total):\n",
        "    classe_dir = os.path.join(train_dir, classe_alvo)\n",
        "    imagens = os.listdir(classe_dir)\n",
        "    num_imagens_atual = len(imagens)\n",
        "\n",
        "    if num_imagens_atual <= novo_total:\n",
        "        print(f\"A classe {classe_alvo} já está balanceada ou tem menos imagens do que o necessário.\")\n",
        "        return\n",
        "\n",
        "    # Selecionar aleatoriamente imagens para remover\n",
        "    imagens_para_remover = random.sample(imagens, num_imagens_atual - novo_total)\n",
        "\n",
        "    # Remover as imagens selecionadas\n",
        "    for imagem in imagens_para_remover:\n",
        "        caminho_imagem = os.path.join(classe_dir, imagem)\n",
        "        os.remove(caminho_imagem)\n",
        "        print(f\"Imagem removida: {caminho_imagem}\")\n",
        "\n",
        "    print(f\"Redução concluída para a classe {classe_alvo}. Total de imagens restantes: {novo_total}\")\n",
        "\n",
        "# Definir o novo número de imagens desejado (1600 imagens)\n",
        "novo_total = 1600\n",
        "\n",
        "# Cortar imagens da classe \"GROCERY\" para que fique com 1600 imagens\n",
        "cortar_imagens_para_balanceamento(train_dir, classe_alvo, novo_total)\n",
        "\n",
        "# Calcular a nova distribuição após o balanceamento\n",
        "nova_distribuicao = calcular_distribuicao_imagens(train_dir)\n",
        "\n",
        "# Plotar o gráfico de barras com a nova distribuição\n",
        "plt.bar(nova_distribuicao.keys(), nova_distribuicao.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Nova Distribuição das Classes de Treinamento\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJc86rI_MBa5"
      },
      "source": [
        "# Parte 2 - Exploração de soluções"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XU0zOsaeMhms"
      },
      "source": [
        "## Objetivo e informações esperadas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SwJ_7YNMpyr"
      },
      "source": [
        "Objetivo:\n",
        "  * Apresentar métodos da literatura e propor ideias para métodos próprios.\n",
        "\n",
        "Informações esperadas:\n",
        "  * Métodos da literatura\n",
        "\n",
        "    1. Todos devem executar um ou mais códigos (exemplos de códigos podem ser encontrados em Related Notebooks no endereço do dataset) que resolvem o problema do projeto.\n",
        "  * Métodos próprios\n",
        "    1. Apresentar ideias que podem melhorar os métodos encontrados e testados da literatura.\n",
        "    2. Ideias para melhorar uma técnica\n",
        "      * Otimização de Hiperparâmetros - alterar ou reduzir os hiperparâmetros.\n",
        "      * Elaborar uma nova arquitetura mais leve para que o treino e o teste sejam rápidos.\n",
        "      * Reduzir número de imagens no treinamento e manter o desempenho.\n",
        "\n",
        "Informações complementares:\n",
        "  * Elaborar uma apresentação para mostrar os métodos da literatura e próprios.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3vqsHMHZuGj9"
      },
      "source": [
        "##Pré-processamento de imagens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ODfT9jOqYXBC"
      },
      "source": [
        "###Normalização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkdUgtC6yKGJ"
      },
      "outputs": [],
      "source": [
        "normalized_dir = os.path.join(data_dir, 'train_normalizadas')\n",
        "\n",
        "# Cria o diretório para as imagens normalizadas, caso não exista\n",
        "if not os.path.exists(normalized_dir):\n",
        "    os.makedirs(normalized_dir)\n",
        "\n",
        "# Loop através de todos os subdiretórios e arquivos\n",
        "for dirpath, dirnames, filenames in os.walk(train_dir):\n",
        "    # Ignora o diretório raiz, se necessário\n",
        "    if dirpath == train_dir:\n",
        "        continue\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Caminho completo do arquivo original\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "\n",
        "        # Leitura da imagem\n",
        "        image = cv2.imread(file_path)\n",
        "\n",
        "        if image is not None:\n",
        "            # Conversão para escala de cinza\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "            # Normalização da imagem\n",
        "            normalized_image = gray_image / 255.0\n",
        "\n",
        "            # Calcula o caminho relativo para manter a estrutura de diretórios\n",
        "            relative_path = os.path.relpath(dirpath, train_dir)\n",
        "            new_dir = os.path.join(normalized_dir, relative_path)\n",
        "\n",
        "            if not os.path.exists(new_dir):\n",
        "                os.makedirs(new_dir)\n",
        "\n",
        "            # Caminho completo para salvar a nova imagem\n",
        "            new_file_path = os.path.join(new_dir, filename)\n",
        "\n",
        "            # Salvar a imagem normalizada\n",
        "            cv2.imwrite(new_file_path, (normalized_image * 255).astype('uint8'))\n",
        "\n",
        "        else:\n",
        "            print(f\"Erro ao carregar a imagem: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "26MlIXnDvQ_S"
      },
      "source": [
        "###Redimensionar tamanho"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xUSfamjsxCZ1"
      },
      "outputs": [],
      "source": [
        "resized_dir = os.path.join(data_dir, 'train_redimensionadas')\n",
        "\n",
        "# Defina o novo tamanho para as imagens (largura, altura)\n",
        "new_size = (300, 200)\n",
        "\n",
        "# Cria o diretório para as imagens redimensionadas, caso não exista\n",
        "if not os.path.exists(resized_dir):\n",
        "    os.makedirs(resized_dir)\n",
        "\n",
        "# Loop através de todos os subdiretórios e arquivos\n",
        "for dirpath, dirnames, filenames in os.walk(train_dir):\n",
        "    # Ignora o diretório raiz, se necessário\n",
        "    if dirpath == train_dir:\n",
        "        continue\n",
        "\n",
        "    for filename in filenames:\n",
        "        # Caminho completo do arquivo original\n",
        "        file_path = os.path.join(dirpath, filename)\n",
        "\n",
        "        # Leitura da imagem\n",
        "        image = cv2.imread(file_path)\n",
        "\n",
        "        if image is not None:\n",
        "            # Redimensionamento da imagem\n",
        "            resized_image = cv2.resize(image, new_size)\n",
        "\n",
        "            # Cria o diretório correspondente dentro de 'train_redimensionadas'\n",
        "            relative_path = os.path.relpath(dirpath, train_dir)\n",
        "            new_dir = os.path.join(resized_dir, relative_path)\n",
        "\n",
        "            if not os.path.exists(new_dir):\n",
        "                os.makedirs(new_dir)\n",
        "\n",
        "            # Caminho completo para salvar a nova imagem\n",
        "            new_file_path = os.path.join(new_dir, filename)\n",
        "\n",
        "            # Salvar a imagem redimensionada\n",
        "            cv2.imwrite(new_file_path, resized_image)\n",
        "\n",
        "        else:\n",
        "            print(f\"Erro ao carregar a imagem: {file_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qve5zba7y8Ey"
      },
      "source": [
        "###Conversão para escala de cinza"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ON-zo9dFy67O"
      },
      "outputs": [],
      "source": [
        "# Configurar os caminhos das pastas\n",
        "source_dir = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train'\n",
        "destination_dir = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_escalacinza'\n",
        "\n",
        "# Criar a pasta de destino se não existir\n",
        "if not os.path.exists(destination_dir):\n",
        "    os.makedirs(destination_dir)\n",
        "\n",
        "def convert_to_grayscale_and_save(source_dir, destination_dir):\n",
        "    for root, dirs, files in os.walk(source_dir):\n",
        "        for file in files:\n",
        "            if file.endswith(('.png', '.jpg', '.jpeg')):\n",
        "                # Caminho completo do arquivo de origem\n",
        "                source_file_path = os.path.join(root, file)\n",
        "\n",
        "                # Caminho completo do arquivo de destino\n",
        "                relative_path = os.path.relpath(root, source_dir)\n",
        "                dest_subdir = os.path.join(destination_dir, relative_path)\n",
        "                dest_file_path = os.path.join(dest_subdir, file)\n",
        "\n",
        "                # Criar subdiretórios no destino, se necessário\n",
        "                if not os.path.exists(dest_subdir):\n",
        "                    os.makedirs(dest_subdir)\n",
        "\n",
        "                # Carregar a imagem\n",
        "                image = cv2.imread(source_file_path)\n",
        "\n",
        "                # Converter para escala de cinza\n",
        "                gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                # Salvar a imagem convertida na pasta de destino\n",
        "                cv2.imwrite(dest_file_path, gray_image)\n",
        "\n",
        "# Converter as imagens e salvar na nova pasta\n",
        "convert_to_grayscale_and_save(source_dir, destination_dir)\n",
        "\n",
        "print(\"Conversão para escala de cinza concluída com sucesso!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3J6vA5exAF4"
      },
      "source": [
        "###Filtragem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDS_N_tJgsoh"
      },
      "source": [
        "####Detectação de bordas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFZ0vpX9iHrt"
      },
      "outputs": [],
      "source": [
        "# Define o caminho da nova pasta de saída\n",
        "output_folder = os.path.join(data_dir, f\"train_detecbordas\")\n",
        "\n",
        "# Certifique-se de que o diretório de saída existe\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "# Itera sobre as pastas (classes)\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        # Cria a pasta correspondente no diretório de saída\n",
        "        output_class_path = os.path.join(output_folder, class_name)\n",
        "        if not os.path.exists(output_class_path):\n",
        "            os.makedirs(output_class_path)\n",
        "\n",
        "        # Itera sobre as imagens dentro da pasta da classe\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Carrega a imagem\n",
        "            image = cv2.imread(image_path, 0)  # Carrega em escala de cinza\n",
        "\n",
        "            # Verifica se a imagem foi carregada corretamente\n",
        "            if image is None:\n",
        "                print(f\"Erro ao carregar a imagem: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Detecta bordas usando o algoritmo de Canny\n",
        "            edges = cv2.Canny(image, 100, 200)\n",
        "\n",
        "            # Define o caminho de saída para a imagem processada\n",
        "            output_image_path = os.path.join(output_class_path, image_name)\n",
        "\n",
        "            # Salva a imagem processada\n",
        "            cv2.imwrite(output_image_path, edges)\n",
        "\n",
        "print(f\"Processamento concluído! Imagens salvas em: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yOmZ4FDZ5bbY"
      },
      "source": [
        "####Realce\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMT9lw5h5rvw"
      },
      "outputs": [],
      "source": [
        "output_folder = os.path.join(data_dir, \"train_realce\")\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        output_class_path = os.path.join(output_folder, class_name)\n",
        "        if not os.path.exists(output_class_path):\n",
        "            os.makedirs(output_class_path)\n",
        "\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "            image_gray = cv2.imread(image_path, 0)\n",
        "            if image_gray is None:\n",
        "                print(f\"Erro ao carregar a imagem: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            clahe_image = clahe.apply(image_gray)\n",
        "            output_image_path = os.path.join(output_class_path, image_name)\n",
        "            cv2.imwrite(output_image_path, clahe_image)\n",
        "\n",
        "print(f\"Processamento concluído! Imagens salvas em: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BeYv0_6Y5mav"
      },
      "source": [
        "####Suavização"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRhZ2P2q5uJn"
      },
      "outputs": [],
      "source": [
        "output_folder = os.path.join(data_dir, \"train_suavizacaomediana\")\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        # Cria a pasta correspondente no diretório de saída\n",
        "        output_class_path = os.path.join(output_folder, class_name)\n",
        "        if not os.path.exists(output_class_path):\n",
        "            os.makedirs(output_class_path)\n",
        "\n",
        "        # Itera sobre as imagens dentro da pasta da classe\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            # Carrega a imagem\n",
        "            image = cv2.imread(image_path, 0)  # Carrega em escala de cinza\n",
        "\n",
        "            # Verifica se a imagem foi carregada corretamente\n",
        "            if image is None:\n",
        "                print(f\"Erro ao carregar a imagem: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            # Aplica o filtro de mediana (com kernel de tamanho 5x5)\n",
        "            median_filtered_image = cv2.medianBlur(image, 5)\n",
        "\n",
        "            # Define o caminho de saída para a imagem processada\n",
        "            output_image_path = os.path.join(output_class_path, image_name)\n",
        "\n",
        "            # Salva a imagem processada\n",
        "            cv2.imwrite(output_image_path, median_filtered_image)\n",
        "\n",
        "print(f\"Processamento concluído! Imagens salvas em: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GAlnqBP5paY"
      },
      "source": [
        "####Correção de contraste"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXupHvHb5QJf"
      },
      "outputs": [],
      "source": [
        "output_folder = os.path.join(data_dir, \"train_contraste\")\n",
        "\n",
        "if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "\n",
        "for class_name in os.listdir(train_dir):\n",
        "    class_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    if os.path.isdir(class_path):\n",
        "        output_class_path = os.path.join(output_folder, class_name)\n",
        "        if not os.path.exists(output_class_path):\n",
        "            os.makedirs(output_class_path)\n",
        "\n",
        "        for image_name in os.listdir(class_path):\n",
        "            image_path = os.path.join(class_path, image_name)\n",
        "\n",
        "            image = cv2.imread(image_path, 0)  # Carrega em escala de cinza\n",
        "\n",
        "            if image is None:\n",
        "                print(f\"Erro ao carregar a imagem: {image_path}\")\n",
        "                continue\n",
        "\n",
        "            equalized_image = cv2.equalizeHist(image)\n",
        "            output_image_path = os.path.join(output_class_path, image_name)\n",
        "            cv2.imwrite(output_image_path, equalized_image)\n",
        "\n",
        "print(f\"Processamento concluído! Imagens salvas em: {output_folder}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5vx8_3ZjvZC"
      },
      "source": [
        "#Prate 3 - Treinamento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PgmmR1iql1hC"
      },
      "outputs": [],
      "source": [
        "train_escalacinza=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_escalacinza'\n",
        "train_detecbordas=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_detecbordas'\n",
        "train_normalizadas=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_normalizadas'\n",
        "train_contraste=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_contraste'\n",
        "train_redimensionadas=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_redimensionadas'\n",
        "train_realce=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_realce'\n",
        "train_suavizacaomediana=r'/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_suavizacaomediana'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XFvQasv8j15A"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import SGD, RMSprop, Adam, Adamax, Nadam, Adagrad, Adadelta\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SODfcFZmkAv9"
      },
      "outputs": [],
      "source": [
        "def filter_hidden_dirs(src_dir, dest_dir):\n",
        "    for item in os.listdir(src_dir):\n",
        "        item_path = os.path.join(src_dir, item)\n",
        "        if not item.startswith('.') and os.path.isdir(item_path):\n",
        "            shutil.copytree(item_path, os.path.join(dest_dir, item))\n",
        "\n",
        "filtered_train_dir = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train_filtered'\n",
        "\n",
        "# Cria o diretório filtrado se não existir\n",
        "if not os.path.exists(filtered_train_dir):\n",
        "    os.makedirs(filtered_train_dir)\n",
        "\n",
        "# Filtra as pastas ocultas\n",
        "filter_hidden_dirs(train_dir, filtered_train_dir)\n",
        "\n",
        "# Define técnicas de aumento de dados\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.2,\n",
        "    shear_range=0.2\n",
        ")\n",
        "\n",
        "# Exemplo de uso do gerador\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    filtered_train_dir,\n",
        "    color_mode='rgb',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J8DCojubkG8-"
      },
      "outputs": [],
      "source": [
        "# Get category labels from the generator\n",
        "labels = train_generator.class_indices\n",
        "\n",
        "# Print labels\n",
        "print(\"Category Labels:\")\n",
        "for category, label in labels.items():\n",
        "    print(f\"{category}: {label}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xcYQ-QXks3y"
      },
      "outputs": [],
      "source": [
        "# Define validation data generator without augmentation\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Example of using the generator for the validation set\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    val_dir,\n",
        "    color_mode = 'rgb',\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    shuffle= False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kmbm1dHUkxj1"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "num_classes = 9\n",
        "epochs = 10\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3, min_lr=1e-6)\n",
        "\n",
        "callbacks = [early_stopping, reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCV-9sx6kzRy"
      },
      "outputs": [],
      "source": [
        "# Define different optimizers\n",
        "optimizers = {\n",
        "    'SGD': SGD(learning_rate=1e-3, momentum=0.9, nesterov=True),\n",
        "    'RMSprop': RMSprop(learning_rate=1e-4),\n",
        "    'Adam': Adam(learning_rate=1e-4),\n",
        "    'Adagrad': Adagrad(learning_rate=1e-4),\n",
        "    'Adadelta': Adadelta(learning_rate=1e-4),\n",
        "    'Adamax': tf.keras.optimizers.Adamax(learning_rate=1e-4),\n",
        "    'Nadam': tf.keras.optimizers.Nadam(learning_rate=1e-4)\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Um5NOPvVVFA"
      },
      "source": [
        "##ResNet50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jnpw22l3VUWd"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import ResNet50\n",
        "\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*img_size, 3))\n",
        "\n",
        "# Add out top layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)  # Ajuste conforme necessário\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Combine the base layer and our top layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers[-20]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Choose the optimizer from optimizers dictionary\n",
        "optimizer_ = optimizers['Adam']\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled and ready for training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "atZRGvs5Y6J9"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDbnvcO0pFX8"
      },
      "outputs": [],
      "source": [
        "# Save the entire model to a file\n",
        "model.save('resnet50.h5')\n",
        "\n",
        "print(\"Model saved to resnet50.h5\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2t7UAnqOiyFb"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "\n",
        "# Get the true labels\n",
        "true_labels = val_generator.classes\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(val_generator, steps=len(val_generator), verbose=1)\n",
        "\n",
        "# Convert predictions to class labels\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_labels, predicted_classes)\n",
        "\n",
        "# Display confusion matrix\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=val_generator.class_indices.keys())\n",
        "disp.plot(cmap=plt.cm.Blues)\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "djebx1Bmi9-b"
      },
      "outputs": [],
      "source": [
        "# Print classification report\n",
        "report = classification_report(true_labels, predicted_classes, target_names=labels)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oducl5yNjBcY"
      },
      "outputs": [],
      "source": [
        "# Function to randomly select an image from the 'check' directory\n",
        "def get_random_image(sample_dataset_dir):\n",
        "    classes = os.listdir(sample_dataset_dir)\n",
        "    selected_class = random.choice(classes)\n",
        "    class_dir = os.path.join(sample_dataset_dir, selected_class)\n",
        "    image_name = random.choice(os.listdir(class_dir))\n",
        "    image_path = os.path.join(class_dir, image_name)\n",
        "    return image_path, selected_class\n",
        "\n",
        "# Function to preprocess the image\n",
        "def preprocess_image(img_path):\n",
        "    # Load the image (this itself is a printable image)\n",
        "    loaded_img = image.load_img(img_path, target_size=(224, 224))\n",
        "    # Convert the image to a numpy array\n",
        "    img = image.img_to_array(loaded_img)\n",
        "    # Reshape the image to add an extra dimension (batch size dimension)\n",
        "    array_image = np.expand_dims(img, axis=0)\n",
        "    # Normalize the image to the range [0, 1]\n",
        "    array_image = array_image / 255.0\n",
        "    return loaded_img, array_image\n",
        "\n",
        "# Display The Image\n",
        "def display_image(img, category, figsize=(5, 5)):\n",
        "    \"Give a loaded image and its category\"\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(img)\n",
        "    plt.title(f\"Chosen Image Actual Category: {category}\")\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YWGOzWwZjEsB"
      },
      "outputs": [],
      "source": [
        "def bring_predict_probas(predictions):\n",
        "    class_labels = {\n",
        "        \"BABY_PRODUCTS\": 0,\n",
        "        \"BEAUTY_HEALTH\": 1,\n",
        "        \"CLOTHING_ACCESSORIES_JEWELLERY\": 2,\n",
        "        \"ELECTRONICS\": 3,\n",
        "        \"GROCERY\": 4,\n",
        "        \"HOBBY_ARTS_STATIONERY\": 5,\n",
        "        \"HOME_KITCHEN_TOOLS\": 6,\n",
        "        \"PET_SUPPLIES\": 7,\n",
        "        \"SPORTS_OUTDOOR\": 8,\n",
        "    }\n",
        "    # Create a reverse mapping\n",
        "    reverse_class_labels = {v: k for k, v in class_labels.items()}\n",
        "    # Flatten the predictions array and sort the probabilities along with their indices\n",
        "    predictions = predictions.flatten()\n",
        "    sorted_indices = np.argsort(predictions)[::-1]  # Sort in descending order\n",
        "    # Get sorted class labels and their corresponding probabilities\n",
        "    sorted_class_labels = [reverse_class_labels[i] for i in sorted_indices]\n",
        "    sorted_probabilities = np.round(predictions[sorted_indices], 2)\n",
        "    return sorted_class_labels, sorted_probabilities\n",
        "\n",
        "\n",
        "# Create a DataFrame\n",
        "def create_dataframe(sorted_class_labels, sorted_probabilities):\n",
        "    df = pd.DataFrame(\n",
        "        {\"Class\": sorted_class_labels, \"Probability\": sorted_probabilities}\n",
        "    )\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZLDy5dXjHXR"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "image_path, image_class = get_random_image(check_dir)\n",
        "loaded_img, array_image = preprocess_image(image_path)\n",
        "predictions = model.predict(array_image)\n",
        "sorted_class_labels, sorted_probabilities = bring_predict_probas(predictions)\n",
        "df = create_dataframe(sorted_class_labels, sorted_probabilities)\n",
        "display_image(loaded_img, image_class)\n",
        "for i in range(10):\n",
        "    image_path, image_class = get_random_image(check_dir)\n",
        "    loaded_img, array_image = preprocess_image(image_path)\n",
        "    predictions = model.predict(array_image)\n",
        "    sorted_class_labels, sorted_probabilities = bring_predict_probas(predictions)\n",
        "    df = create_dataframe(sorted_class_labels, sorted_probabilities)\n",
        "\n",
        "    # Exibir a imagem e a classe prevista\n",
        "    display_image(loaded_img, image_class)\n",
        "\n",
        "    print(f\"Image {i+1} - Actual Category: {image_class}\")\n",
        "    print(\"Model Predicts: \")\n",
        "    print(df)\n",
        "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3kLn0nT9tUyB"
      },
      "source": [
        "##MobileNetV2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyc7il5uk3mF"
      },
      "outputs": [],
      "source": [
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(*img_size, 3))\n",
        "\n",
        "# Add out top layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Combine the base layer and our top layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Choose the optimizer from optimizers dictionary\n",
        "optimizer_ = optimizers['Adam']\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled and ready for training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S-DhG8RimqDk"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=20,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etkYsdW_zuxJ"
      },
      "source": [
        "## EfficientNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ofaislQz0xJ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import EfficientNetB0\n",
        "\n",
        "base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(*img_size, 3))\n",
        "\n",
        "# Add out top layers\n",
        "x = base_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)  # Ajuste conforme necessário\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "predictions = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "# Combine the base layer and our top layers\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the base model layers\n",
        "for layer in base_model.layers[-20]:\n",
        "    layer.trainable = True\n",
        "\n",
        "# Choose the optimizer from optimizers dictionary\n",
        "optimizer_ = optimizers['Adam']\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=optimizer_, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"Model compiled and ready for training.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5BosL9oz68Z"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=30,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "print(\"Training complete.\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "DmSO99PpAOSo",
        "26MlIXnDvQ_S",
        "yOmZ4FDZ5bbY"
      ],
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
