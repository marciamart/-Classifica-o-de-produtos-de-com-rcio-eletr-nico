{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marciamart/Classificacao-Ecommerce/blob/main/classifica%C3%A7%C3%A3o_ecommerce.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install opendatasets"
      ],
      "metadata": {
        "id": "CAKM9t2gvbzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download(\"https://www.kaggle.com/datasets/fatihkgg/ecommerce-product-images-18k\")\n",
        "\n",
        "#USAR API TOKEN DO KAGGLE"
      ],
      "metadata": {
        "id": "UtwCMKa7vyxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset em  /content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES"
      ],
      "metadata": {
        "id": "J2DbowIZCOG4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES'"
      ],
      "metadata": {
        "id": "eQK9tRfvbWv6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parte 1 - Análise do DataSet"
      ],
      "metadata": {
        "id": "APdfWgpjB5ki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Objetivo e informações esperadas"
      ],
      "metadata": {
        "id": "wAqP_BIlDlr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Objetivo:\n",
        "* Apresentar informações do dataset.\n",
        "\n",
        "Informações esperadas:\n",
        "* Integridade dos Arquivos\n",
        "  1. Verifique se todas as imagens listadas no arquivo de informações\n",
        "realmente existem no diretório de imagens e vice-versa.\n",
        "  2. Verifique se todas as imagens estão no mesmo formato, ex: JPEG,\n",
        "PNG, etc.\n",
        "* Consistência dos Metadados\n",
        "  1. Verifique se há valores ausentes nos metadados e como esses casos\n",
        "são tratados.\n",
        "  2. Verifique valores inconsistentes, por exemplo: dimensões de imagens\n",
        "fora do esperado.\n",
        "* Qualidade das Imagens\n",
        "  1. Identifique imagens corrompidas que não podem ser abertas ou\n",
        "processadas.\n",
        "* Distribuição das Classes\n",
        "  1. Verifique a distribuição das classes para identificar possíveis\n",
        "desequilíbrios que possam afetar a modelagem\n",
        "* Duplicatas\n",
        "  1. Identifique imagens duplicadas que possam enviesar os resultados.\n",
        "  2. Verifique duplicatas no arquivo de informações.\n",
        "\n",
        "Informações complementares:\n",
        "* Elaborar uma apresentação para mostrar os resultados.\n",
        "* Apresentar o dataset de forma detalhada.\n",
        "* Verifique quais itens em Informações esperadas podem ser aplicados no\n",
        "dataset."
      ],
      "metadata": {
        "id": "htOu5f-OD6pq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Integridade dos Arquivos**\n",
        "A função a seguir verifica se todas as imagens no diretório estão no mesmo formato (JPEG, JPG, PNG). Ela retorna um dicionário com os formatos das imagens como chaves e suas respectivas quantidades como valores.\n",
        "\n",
        "Saída esperada: {'JPEG': 18175}"
      ],
      "metadata": {
        "id": "k8IhDPpHS5lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "def verificar_formato_imagem(data):\n",
        "    formatos = {}\n",
        "    for raiz, dirs, arquivos in os.walk(data):\n",
        "        for arquivo in arquivos:\n",
        "            if arquivo.endswith(('jpeg', 'jpg', 'png')):\n",
        "                caminho_arquivo = os.path.join(raiz, arquivo)\n",
        "                with Image.open(caminho_arquivo) as img:\n",
        "                    formato = img.format\n",
        "                    if formato not in formatos:\n",
        "                        formatos[formato] = 0\n",
        "                    formatos[formato] += 1\n",
        "            else:\n",
        "                formatos['Desconhecido'] = formatos.get('Desconhecido', 0) + 1\n",
        "\n",
        "    return formatos\n",
        "\n",
        "formatos_imagens = verificar_formato_imagem(data)\n",
        "print(formatos_imagens)"
      ],
      "metadata": {
        "id": "GNPu1t5YRZks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Consistência dos Metadados**\n",
        "\n",
        "Nessa etapa, foi analisado a qualidade e a integridade das imagens, para assegurar que não haverá maiores problemas nas etapas seguintes.\n",
        "\n",
        "Foram levantados os seguintes:\n",
        "\n",
        "\n",
        "*   Dimensões das imagens\n",
        "*   Quantidade de megapixes\n",
        "*   Recorrência de cores\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "h1ZERpxr50AR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install libimage-exiftool-perl\n",
        "#Ferramenta utilizada para leitura de metadados de imagens\n",
        "\n",
        "!pip install colorgram.py\n",
        "# Lib utilizada para a extrair cores predominantes de uma imagem"
      ],
      "metadata": {
        "id": "p_yFZfex-Lpd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Dimensão das imagens**\n",
        "\n",
        "Utilizando o conjunto de imagens amostrais, presentes na pasta (train), não foi encontrado alguma inconsistência, uma vez que o conjunto amostral apresenta imagens com as mesmas dimensões.\n",
        "\n",
        "---\n",
        "*Saída Esperada*:\n",
        "\n",
        "\n",
        "```\n",
        "A dimensão que mais aparece é: (224, 224) (quantidade: 551)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "t2EvBVCB8pue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import imghdr\n",
        "from collections import Counter\n",
        "\n",
        "pasta_check = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "\n",
        "contagem_dimensoes = Counter()\n",
        "\n",
        "def verificar_dimensoes_imagens(pasta):\n",
        "    for item in os.listdir(pasta):\n",
        "        caminho_item = os.path.join(pasta, item)\n",
        "\n",
        "        if os.path.isdir(caminho_item):\n",
        "            verificar_dimensoes_imagens(caminho_item)\n",
        "        elif os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "            resultado = subprocess.run([\"exiftool\", \"-s\", \"-ImageWidth\", \"-ImageHeight\", caminho_item], capture_output=True, text=True)\n",
        "\n",
        "            dimensoes = resultado.stdout.strip().split(\"\\n\")\n",
        "            largura = int(dimensoes[0].split(\": \")[1])\n",
        "            altura = int(dimensoes[1].split(\": \")[1])\n",
        "\n",
        "            contagem_dimensoes[(largura, altura)] += 1\n",
        "\n",
        "verificar_dimensoes_imagens(pasta_check)\n",
        "\n",
        "dimensao_mais_comum = contagem_dimensoes.most_common(1)[0]\n",
        "\n",
        "print(f\"A dimensão que mais aparece é: {dimensao_mais_comum[0]} (quantidade: {dimensao_mais_comum[1]})\")\n"
      ],
      "metadata": {
        "id": "OHoS2wfA8CeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Quantidade de MegaPixels**\n",
        "\n",
        "Também não foi encontrado dados ausentes ou inconsistentes nesse espaço de dados amostral, uma vez que todas as imagens apresentam a mesma quantidade de megapixels.\n",
        "\n",
        "---\n",
        "*Saída Esperada:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Todos os arquivos possuem 0.050 megapixels.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Vh6fkU3a7yWv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "import imghdr\n",
        "\n",
        "pasta_check = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "\n",
        "megapixels_esperado = None\n",
        "arquivos_com_megapixels_diferentes = []\n",
        "\n",
        "def verificar_megapixels(pasta):\n",
        "    global megapixels_esperado, arquivos_com_megapixels_diferentes\n",
        "\n",
        "    for item in os.listdir(pasta):\n",
        "        caminho_item = os.path.join(pasta, item)\n",
        "\n",
        "        if os.path.isdir(caminho_item):\n",
        "            verificar_megapixels(caminho_item)\n",
        "        elif os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "            resultado = subprocess.run([\"exiftool\", \"-s\", \"-Megapixels\", caminho_item], capture_output=True, text=True)\n",
        "\n",
        "            megapixels_atual = resultado.stdout.strip().split(\": \")[1]\n",
        "\n",
        "            if megapixels_esperado is None:\n",
        "                megapixels_esperado = megapixels_atual\n",
        "            elif megapixels_atual != megapixels_esperado:\n",
        "                arquivos_com_megapixels_diferentes.append(caminho_item)\n",
        "\n",
        "verificar_megapixels(pasta_check)\n",
        "\n",
        "if arquivos_com_megapixels_diferentes:\n",
        "    print(\"Nem todos os arquivos possuem o mesmo valor de megapixels.\")\n",
        "    print(\"Arquivos com megapixels diferentes:\")\n",
        "    for arquivo in arquivos_com_megapixels_diferentes:\n",
        "        print(f\"  - {arquivo}\")\n",
        "else:\n",
        "    print(f\"Todos os arquivos possuem {megapixels_esperado} megapixels.\")\n"
      ],
      "metadata": {
        "id": "NHUdnZJa_cdW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **Recorrência de Cores**\n",
        "\n",
        "Nesse levantamento, foi observado que as cores semelhantes ao branco absoluto são as mais presentes nas categorias apresentadas. O algoritmo utilizado analisa a imagem como um todoo, por isso, o fundo \"neutro\" influênciou nesse resultado. Porém, utilizando o *OpenCV*, é possível detectar os contornos do produto e descobrir as cores além do fundo neutro.\n",
        "\n",
        "\n",
        "---\n",
        "*Saída utilizando apenas a biblioteca Colorgram:*\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Categoria 'BABY_PRODUCTS': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 3.05\n",
        "Categoria 'BEAUTY_HEALTH': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 2.03\n",
        "Categoria 'CLOTHING_ACCESSORIES_JEWELLERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 6.29\n",
        "Categoria 'ELECTRONICS': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 4.57\n",
        "Categoria 'GROCERY': Cor predominante: Rgb(r=254, g=254, b=253), Proporção total: 9.50\n",
        "Categoria 'HOBBY_ARTS_STATIONERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 2.84\n",
        "Categoria 'HOME_KITCHEN_TOOLS': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 8.90\n",
        "Categoria 'PET_SUPPLIES': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 2.11\n",
        "Categoria 'SPORTS_OUTDOOR': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 12.45\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DmSO99PpAOSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import colorgram\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import imghdr\n",
        "\n",
        "pasta_check = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "\n",
        "def analisar_cores_por_categoria(pasta):\n",
        "    dados = []\n",
        "\n",
        "    for nome_subpasta in os.listdir(pasta):\n",
        "        caminho_subpasta = os.path.join(pasta, nome_subpasta)\n",
        "        if os.path.isdir(caminho_subpasta):\n",
        "            categoria = nome_subpasta\n",
        "\n",
        "            for item in os.listdir(caminho_subpasta):\n",
        "                caminho_item = os.path.join(caminho_subpasta, item)\n",
        "                if os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "                    try:\n",
        "                        cores = colorgram.extract(Image.open(caminho_item), 5)  # Extrai 5 cores\n",
        "\n",
        "                        for cor in cores:\n",
        "                            dados.append({'categoria': categoria, 'cor_predominante': cor.rgb, 'proporcao': cor.proportion})\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao processar a imagem {caminho_item}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(dados)\n",
        "\n",
        "    cores_predominantes_por_categoria = df.groupby(['categoria', 'cor_predominante'])['proporcao'].sum().reset_index()\n",
        "    cores_predominantes_por_categoria = cores_predominantes_por_categoria.loc[cores_predominantes_por_categoria.groupby('categoria')['proporcao'].idxmax()]\n",
        "\n",
        "    for _, row in cores_predominantes_por_categoria.iterrows():\n",
        "        print(f\"Categoria '{row['categoria']}': Cor predominante: {row['cor_predominante']}, Proporção total: {row['proporcao']:.2f}\")\n",
        "\n",
        "analisar_cores_por_categoria(pasta_check)"
      ],
      "metadata": {
        "id": "K9LDhAGFCpwQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Após utilizar a ferramenta *OpenCV*, conseguimos observar que, apesar da maioria das categorias ainda seguir na paleta de cores \"branco\" ou \"cinza\", a  categoria \"BEAUTY_HEALTH\" tem uma predominância de cores mais vibrantes e quentes, como o amarelo alaranjado, que podem transmitir a ideia de saúde, vitalidade e beleza, enquanto \"BABY_PRODUCTS\" tem uma predominância de cores claras e neutras, como o branco e o cinza claro, que são comumente associadas a produtos para bebês.\n",
        "\n",
        "Cada categoria apresenta a seguinte variedade de cores:\n",
        "\n",
        "\n",
        "*   BABY_PRODUCTS - **Cinza claro.**\n",
        "*   HOME_KITCHEN_TOOLS - **Cinza bem claro.**\n",
        "*   GROCERY - **Um branco com tons de amarelo.**\n",
        "*   BEAUTY_HEALTH - **Dourado.**\n",
        "*   CLOTHING_ACCESSORIES_JEWELLERY, ELECTRONICS, HOBBY_ARTS_STATIONERY, PET_SUPPLIES e SPORTS_OUTDOOR - **Branco.**\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "*Saída Esperada:*\n",
        "\n",
        "\n",
        ">A proporção total indica o percentual que os metadados da categoria representam em relação ao total de dados.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "Categoria 'BABY_PRODUCTS': Cor predominante: Rgb(r=237, g=237, b=236), Proporção total: 1.73\n",
        "Categoria 'BEAUTY_HEALTH': Cor predominante: Rgb(r=226, g=165, b=4), Proporção total: 1.20\n",
        "Categoria 'CLOTHING_ACCESSORIES_JEWELLERY': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 1.09\n",
        "Categoria 'ELECTRONICS': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 3.55\n",
        "Categoria 'GROCERY': Cor predominante: Rgb(r=254, g=254, b=253), Proporção total: 1.69\n",
        "Categoria 'HOBBY_ARTS_STATIONERY': Cor predominante: Rgb(r=254, g=254, b=254), Proporção total: 1.20\n",
        "Categoria 'HOME_KITCHEN_TOOLS': Cor predominante: Rgb(r=251, g=251, b=250), Proporção total: 1.61\n",
        "Categoria 'PET_SUPPLIES': Cor predominante: Rgb(r=253, g=253, b=253), Proporção total: 1.76\n",
        "Categoria 'SPORTS_OUTDOOR': Cor predominante: Rgb(r=252, g=252, b=252), Proporção total: 3.87\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OOsd7cMTDH93"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import colorgram\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import imghdr\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "pasta_check = '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "\n",
        "def analisar_cores_por_categoria(pasta):\n",
        "    dados = []\n",
        "\n",
        "    for nome_subpasta in os.listdir(pasta):\n",
        "        caminho_subpasta = os.path.join(pasta, nome_subpasta)\n",
        "        if os.path.isdir(caminho_subpasta):\n",
        "            categoria = nome_subpasta\n",
        "\n",
        "            for item in os.listdir(caminho_subpasta):\n",
        "                caminho_item = os.path.join(caminho_subpasta, item)\n",
        "                if os.path.isfile(caminho_item) and imghdr.what(caminho_item) == 'jpeg':\n",
        "                    try:\n",
        "                        img = cv2.imread(caminho_item)\n",
        "                        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "                        _, thresh = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY_INV)\n",
        "\n",
        "                        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "                        if len(contours) > 0:\n",
        "                            maior_contorno = max(contours, key=cv2.contourArea)\n",
        "                            x, y, w, h = cv2.boundingRect(maior_contorno)\n",
        "                            img_recortada = img[y:y+h, x:x+w]\n",
        "\n",
        "                            cores = colorgram.extract(Image.fromarray(img_recortada), 5)\n",
        "\n",
        "                            for cor in cores:\n",
        "                                dados.append({'categoria': categoria, 'cor_predominante': cor.rgb, 'proporcao': cor.proportion})\n",
        "                        else:\n",
        "                            print(f\"Nenhum contorno encontrado na imagem {caminho_item}.\")\n",
        "\n",
        "                    except Exception as e:\n",
        "                        print(f\"Erro ao processar a imagem {caminho_item}: {e}\")\n",
        "\n",
        "    df = pd.DataFrame(dados)\n",
        "\n",
        "    cores_predominantes_por_categoria = df.groupby(['categoria', 'cor_predominante'])['proporcao'].sum().reset_index()\n",
        "    cores_predominantes_por_categoria = cores_predominantes_por_categoria.loc[cores_predominantes_por_categoria.groupby('categoria')['proporcao'].idxmax()]\n",
        "\n",
        "    for _, row in cores_predominantes_por_categoria.iterrows():\n",
        "        print(f\"Categoria '{row['categoria']}': Cor predominante: {row['cor_predominante']}, Proporção total: {row['proporcao']:.2f}\")\n",
        "\n",
        "analisar_cores_por_categoria(pasta_check)\n"
      ],
      "metadata": {
        "id": "Jtyjw9EkDHjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Qualidade de imagens**"
      ],
      "metadata": {
        "id": "OwKzJIstGDAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "#Verifica se uma imagem pode ser aberta.\n",
        "def check_image(image_path):\n",
        "  try:\n",
        "    img = cv2.imread(image_path)\n",
        "    return img is not None\n",
        "  except Exception as e:\n",
        "    print(f\"Erro ao abrir {image_path}: {str(e)}\")\n",
        "    return False\n",
        "\n",
        "#Encontra imagens corrompidas em um diretório e seus subdiretórios.\n",
        "def find_corrupted_images(directory):\n",
        "  \"\"\"Encontra imagens corrompidas em um diretório e seus subdiretórios.\n",
        "\n",
        "  Args:\n",
        "    directory: Caminho para o diretório raiz.\n",
        "\n",
        "  Returns:\n",
        "    Uma lista com os caminhos das imagens corrompidas.\n",
        "  \"\"\"\n",
        "  corrupted_images = []\n",
        "  for root, _, files in os.walk(directory):\n",
        "    for file in files:\n",
        "      if file.endswith(('.jpg', '.jpeg', '.png')):  # Adapte para outros formatos se necessário\n",
        "        image_path = os.path.join(root, file)\n",
        "        if not check_image(image_path):\n",
        "          corrupted_images.append(image_path)\n",
        "  return corrupted_images\n",
        "\n",
        "# Definindo os caminhos dos seus diretórios\n",
        "train_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train\"\n",
        "val_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/val\"\n",
        "test_dir = \"/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check\"\n",
        "\n",
        "# Encontrando as imagens corrompidas em cada diretório\n",
        "corrupted_train = find_corrupted_images(train_dir)\n",
        "corrupted_val = find_corrupted_images(val_dir)\n",
        "corrupted_test = find_corrupted_images(test_dir)\n",
        "\n",
        "# Imprimindo ou salvando os resultados\n",
        "print(\"Imagens corrompidas no conjunto de treinamento:\")\n",
        "print(corrupted_train)"
      ],
      "metadata": {
        "id": "6YaOOzndGqtP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Distribuição das Classes**\n",
        "Conjuntos de treinamento (train) e validação (val) para treinamento de modelo e ajuste de hiperparâmetros. E uma pequena amostra, conjunto de verificação (check) para avaliação visual do modelo durante a implantação.\n",
        "\n",
        "Aqui faremos uma análise da distribuição das imagens nessas classes."
      ],
      "metadata": {
        "id": "Y2kMdTKdakBr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####**TRAIN**"
      ],
      "metadata": {
        "id": "TslbwNuMUEhu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aqui contaremos quantas imagens possui em cada classe (diretórios)"
      ],
      "metadata": {
        "id": "lNkPBNR064ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ],
      "metadata": {
        "id": "2oS8ujnAa23-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criando um gráfico de barras para visualização da distribuição das classes"
      ],
      "metadata": {
        "id": "0-bRIcq-7Fza"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Treinamento\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tk0zOzrBbBC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com a análise podemos observar que a classe GROCERY possui significativamente mais instâncias em comparação com as demais classes, sugerindo um desequilíbrio considerável na distribuição das classes no conjunto de dados."
      ],
      "metadata": {
        "id": "YOBG30hN994w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **CHECK - VAL**\n",
        "Faremos o mesmo para o conjunto de validação (val) e conjunto de verificação (check)"
      ],
      "metadata": {
        "id": "-U1ctGiN7n9u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **VAL**"
      ],
      "metadata": {
        "id": "Xd9N4unc7OBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/val'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ],
      "metadata": {
        "id": "pdVSfuRb89Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Validação\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HsFjxJ4u9GLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **CHECK**"
      ],
      "metadata": {
        "id": "ni-LNizE9R7m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "#análise da distribuição da classe: TRAIN\n",
        "data =  '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check'\n",
        "subdiretorios = {}\n",
        "# Passando por cada subdiretório\n",
        "for dirpath, dirnames, filenames in os.walk(data):\n",
        "    if dirpath == data: continue\n",
        "\n",
        "    num_images = 0\n",
        "    # Conta o número de imagens no subdiretório\n",
        "    for filename in filenames:\n",
        "        if filename.lower().endswith('.jpeg'):\n",
        "            num_images += 1\n",
        "\n",
        "    # Imprimi o número de imagens do subdiretório atual\n",
        "    print(f\"São {num_images} imagens no diretório {os.path.basename(dirpath)}\")\n",
        "    subdiretorios[os.path.basename(dirpath)] = num_images\n",
        "\n",
        "print(f\"Subdiretórios: {subdiretorios}\")"
      ],
      "metadata": {
        "id": "4hQ2SeaV9ltV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.bar(subdiretorios.keys(), subdiretorios.values())\n",
        "plt.xticks(rotation=90)\n",
        "plt.ylabel(\"Quantidade de Imagens\")\n",
        "plt.title(\"Distribuição das Classes de Verificação\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "GQJiv2iO9cOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Duplicatas**\n",
        "\n",
        "\n",
        "1.   Identifique imagens duplicadas que possam enviesar os resultados.\n",
        "\n",
        "2.   Verifique duplicatas no arquivo de informações."
      ],
      "metadata": {
        "id": "btBPDi0uw2l8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install imagehash"
      ],
      "metadata": {
        "id": "P3MlEKlTa6Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import imagehash\n",
        "\n",
        "# Diretórios contendo as imagens\n",
        "data_dirs = [\n",
        "    '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/check',\n",
        "    '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/train',\n",
        "    '/content/ecommerce-product-images-18k/ECOMMERCE_PRODUCT_IMAGES/val'\n",
        "]\n",
        "\n",
        "# Função para calcular hash de uma imagem\n",
        "def calculate_image_hash(image_path):\n",
        "    with Image.open(image_path) as img:\n",
        "        return imagehash.phash(img)\n",
        "\n",
        "# Identificar imagens duplicadas\n",
        "image_hashes = {}\n",
        "duplicates = []\n",
        "dir_duplicate_counts = {dir: 0 for dir in data_dirs}\n",
        "\n",
        "# Caminhar pelos diretórios de dados e processar as imagens\n",
        "for data in data_dirs:\n",
        "    for dirpath, dirnames, filenames in os.walk(data):\n",
        "        for filename in filenames:\n",
        "            if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_path = os.path.join(dirpath, filename)\n",
        "                img_hash = calculate_image_hash(image_path)\n",
        "\n",
        "                if img_hash in image_hashes:\n",
        "                    duplicates.append((filename, image_hashes[img_hash]))\n",
        "                    # Incrementar o contador de duplicatas para o diretório atual\n",
        "                    dir_duplicate_counts[data] += 1\n",
        "                else:\n",
        "                    image_hashes[img_hash] = filename\n",
        "\n",
        "# Imprimir imagens duplicadas\n",
        "print(\"Imagens duplicadas:\")\n",
        "for dup in duplicates:\n",
        "    print(f\"{dup[0]} -> {dup[1]}\")\n",
        "\n",
        "# Imprimir contagem de duplicatas por diretório\n",
        "print(\"\\nContagem de duplicatas por diretório:\")\n",
        "for dir, count in dir_duplicate_counts.items():\n",
        "    print(f\"{dir}: {count} duplicatas\")\n",
        "\n",
        "# Imprimir contagem total de duplicatas\n",
        "total_duplicates = sum(dir_duplicate_counts.values())\n",
        "print(f\"\\nTotal de duplicatas: {total_duplicates}\")\n",
        "\n",
        "# Se desejar salvar os resultados\n",
        "# with open('duplicated_images.txt', 'w') as f:\n",
        "#     for dup in duplicates:\n",
        "#         f.write(f\"{dup[0]} -> {dup[1]}\\n\")"
      ],
      "metadata": {
        "id": "HXDlFYENePxp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}